# Data Engineer Modul

Kurze Beschreibung des Moduls und aller enthaltenen Materialien (Skripte, PrÃ¤sentationen, Dokumente). Diese README dient als Einstiegspunkt und Inhaltsverzeichnis.

## ğŸ¯ Ziel & Lernziele

* Datenintegration (ETL): Extraktion, Transformation, Laden
* Datenmodellierung: ERâ€‘Modell, Star-/Snowflakeâ€‘Schema
* Data Warehousing: Dimensionen/Fakten, **SCD (v.â€¯a. SCD0/SCD2)**
* DatenqualitÃ¤t & Bereinigung (inkl. **RegEx**â€‘Beispiele)
* SQL/Tâ€‘SQL & Python (Pandas) fÃ¼r Datenpipelines

## ğŸ“¦ Inhalt / DateiÃ¼bersicht

> Hinweis: Liste basiert auf dem aktuellen Stand der bereitgestellten Dateien. Bitte ergÃ¤nzen/aktualisieren, falls neue Dateien hinzukommen.

* **Ordner** `KLR-164/` â€“ Unterlagen/Ãœbungen zum Themenblock KLRâ€‘164
* **Ordner** `PrÃ¤sentation/` â€“ Folien & Materialien

  * `Reisebuero_DWH_Praesentation.pptx`
  * `Reisebuero_DWH_Praesentation_mit_Diagrammen.pptx`
* **Ordner** `Projekt/` â€“ Projektdateien (ReisebÃ¼roâ€‘DWH, SQL/ETL, Begleitcode)
* **Ordner** `Ressourcen/` â€“ Begleitmaterial (Artikel, Vorlagen, Referenzen)
* **Skript** `Gold_daten_vorbereitung.py` â€“ Pythonâ€‘ETL fÃ¼r Goldâ€‘Layer (Pandas)
* **Dokument** `Lasten-/Pflichtenheft.pdf` â€“ Anforderungen & Abgrenzungen
* **Dokument** `Data-Warehouse-Blueprints.pdf` â€“ Architektur/Schemaâ€‘EntwÃ¼rfe
* **Artikel** `Top 5 Data Cleansing Tools, die jeder Datenprofi kennen sollte.htm`
* **Dokument** `PythonT-SQL vs.SSIS.pdf` â€“ GegenÃ¼berstellung von ETLâ€‘AnsÃ¤tzen

> Falls weitere Dateien/Unterordner existieren (z.â€¯B. `sql/`, `data/`), bitte hier ergÃ¤nzen.

## ğŸ—‚ï¸ Empfohlene Ordnerstruktur (optional)

```
Modul-Data-Engineer/
â”œâ”€ scripts/                  # Python, Hilfsskripte
â”œâ”€ sql/                      # DDL/DML, Views, Prozeduren
â”œâ”€ docs/                     # PDFs, Lasten-/Pflichtenheft, Blueprints
â”œâ”€ presentations/            # PPTX
â”œâ”€ data/
â”‚  â”œâ”€ raw/                   # Rohdaten
â”‚  â”œâ”€ staging/               # Zwischenschritte
â”‚  â”œâ”€ curated/               # bereinigte/vereinheitlichte Daten
â”‚  â””â”€ gold/                  # auslieferungsreife Data Marts
â””â”€ README.md
```

## ğŸ§ª Quickstart (Pythonâ€‘ETL)

Voraussetzungen: **Python 3.10+**, `pip install -r requirements.txt` (falls vorhanden).

```bash
# Beispiel: Skript ausfÃ¼hren (Pfade im Skript anpassen)
python Gold_daten_vorbereitung.py
```

### Typische Bibliotheken

* `pandas`, `numpy`, `pyyaml` (Konfiguration), ggf. `sqlalchemy`/Datenbanktreiber

## ğŸ§° Quickstart (SQL/Tâ€‘SQL)

* DDL/ETLâ€‘Skripte in `sql/` ausfÃ¼hren (Reihenfolge beachten)
* SCD2: Historisierung Ã¼ber `valid_from`, `valid_to`, `is_current`
* Indizes/Constraints nachladen, Queryâ€‘PlÃ¤ne prÃ¼fen

## ğŸ›ï¸ Dataâ€‘Warehouse (ReisebÃ¼roâ€‘Case)

* **Dimensionen** (z.â€¯B. Kunde, Zeit, Artikel, Filiale, Mitarbeiter)
* **Fakten** (z.â€¯B. Buchung/Verkauf)
* **SCD**: Stammdatenhistorie (z.â€¯B. AdressÃ¤nderungen)
* **Starâ€‘Schema** mit klaren FremdschlÃ¼sselâ€‘Beziehungen

## ğŸ§¼ DatenqualitÃ¤t & Bereinigung

* Dubletten, fehlende Werte, inkonsistente Formate
* RegExâ€‘basierte Normalisierung (Telefonnummern, PLZ, Eâ€‘Mail, IDs)
* Validierung per Constraints/Checks

## ğŸ” ETLâ€‘Prozess (Beispielâ€‘Stufen)

1. **Extract**: CSV/Excel/DB â†’ `raw/`
2. **Transform**: Typen, Mapping, Keys, SCDâ€‘Logik â†’ `staging/`
3. **Load**: Dimensionen & Fakten â†’ `curated/`/`gold/`

## ğŸ“ Versionierung & Commits

* AussagekrÃ¤ftige Messages (z.â€¯B. `feat:`, `fix:`, `docs:`)
* GroÃŸe BinÃ¤rdateien (PPTX/PDF) vorzugsweise mit Git LFS verwalten

## ğŸ“„ Lizenz & Nutzung

* Interne Ausbildungsunterlagen; bei externer Nutzung bitte Lizenz ergÃ¤nzen (z.â€¯B. MIT) und Quellen angeben.

## ğŸ‘¤ Kontakt

Tanja Koschevnikov
GitHub: [https://github.com/Skalae581](https://github.com/Skalae581)
